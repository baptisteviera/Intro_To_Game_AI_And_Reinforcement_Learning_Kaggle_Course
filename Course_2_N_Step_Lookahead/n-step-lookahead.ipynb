{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Introduction\n\nIn the previous tutorial, you learned how to build an agent with one-step lookahead.  This agent performs reasonably well, but definitely still has room for improvement!  For instance, consider the potential moves in the figure below.  (_Note that we use zero-based numbering for the columns, so the leftmost column corresponds to `col=0`, the next column corresponds to `col=1`, and so on._)\n\n<center>\n<img src=\"https://i.imgur.com/aAYyy2I.png\" width=90%><br/>\n</center>\n\nWith one-step lookahead, the red player picks one of column 5 or 6, each with 50% probability.  But, column 5 is clearly a bad move, as it lets the opponent win the game in only one more turn.  Unfortunately, the agent doesn't know this, because it can only look one move into the future.  \n\nIn this tutorial, you'll use the **minimax algorithm** to help the agent look farther into the future and make better-informed decisions.\n\n# Minimax\n\nWe'd like to leverage information from deeper in the game tree.  For now, assume we work with a depth of 3.  This way, when deciding its move, the agent considers all possible game boards that can result from  \n1. the agent's move, \n2. the opponent's move, and \n3. the agent's next move.  \n\nWe'll work with a visual example.  For simplicity, we assume that at each turn, both the agent and opponent have only two possible moves.  Each of the blue rectangles in the figure below corresponds to a different game board.\n\n<center>\n<img src=\"https://i.imgur.com/BrRe7Bu.png\" width=90%><br/>\n</center>\n\nWe have labeled each of the \"leaf nodes\" at the bottom of the tree with the score from the heuristic.  (_We use made-up scores in the figure.  In the code, we'll use the same heuristic from the previous tutorial._)  As before, the current game board is at the top of the figure, and the agent's goal is to end up with a score that's as high as possible. \n\nBut notice that the agent no longer has complete control over its score -- after the agent makes its move, the opponent selects its own move.  And, the opponent's selection can prove disastrous for the agent!  In particular, \n- If the agent chooses the left branch, the opponent can force a score of -1.  \n- If the agent chooses the right branch, the opponent can force a score of +10.  \n\nTake the time now to check this in the figure, to make sure it makes sense to you!\n\nWith this in mind, you might argue that the right branch is the better choice for the agent, since it is the less risky option.  Sure, it gives up the possibility of getting the large score (+40) that can only be accessed on the left branch, but it also guarantees that the agent gets at least +10 points.\n\nThis is the main idea behind the **minimax algorithm**: the agent chooses moves to get a score that is as high as possible, and it assumes the opponent will counteract this by choosing moves to force the score to be as low as possible.  That is, the agent and opponent have opposing goals, and we assume the opponent plays optimally.\n\nSo, in practice, how does the agent use this assumption to select a move?  We illustrate the agent's thought process in the figure below.\n\n<center>\n<img src=\"https://i.imgur.com/bWezUC3.png\" width=90%><br/>\n</center>\n\nIn the example, minimax assigns the move on the left a score of -1, and the move on the right is assigned a score of +10.  So, the agent will select the move on the right. \n\n# Code\n\nWe'll use several functions from the previous tutorial.  These are defined in the hidden code cell below.  (_Click on the \"Code\" button below if you'd like to view them._)"},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"\nimport random\nimport numpy as np\n\n# Gets board at next step if agent drops piece in selected column\ndef drop_piece(grid, col, mark, config):\n    next_grid = grid.copy()\n    for row in range(config.rows-1, -1, -1):\n        if next_grid[row][col] == 0:\n            break\n    next_grid[row][col] = mark\n    return next_grid\n\n# Helper function for get_heuristic: checks if window satisfies heuristic conditions\ndef check_window(window, num_discs, piece, config):\n    return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n    \n# Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\ndef count_windows(grid, num_discs, piece, config):\n    num_windows = 0\n    # horizontal\n    for row in range(config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[row, col:col+config.inarow])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n    # vertical\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns):\n            window = list(grid[row:row+config.inarow, col])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n    # positive diagonal\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n    # negative diagonal\n    for row in range(config.inarow-1, config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n    return num_windows"},{"cell_type":"markdown","metadata":{},"source":"We'll also need to slightly modify the heuristic from the previous tutorial, since the opponent is now able to modify the game board.\n\n<center>\n<img src=\"https://i.imgur.com/vQ8b1aX.png\" width=70%><br/>\n</center>\n\nIn particular, we need to check if the opponent has won the game by playing a disc.  The new heuristic looks at each group of four adjacent locations in a (horizontal, vertical, or diagonal) line and assigns:\n- **1000000 (`1e6`) points** if the agent has four discs in a row (the agent won), \n- **1 point** if the agent filled three spots, and the remaining spot is empty (the agent wins if it fills in the empty spot), \n- **-100 points** if the opponent filled three spots, and the remaining spot is empty (the opponent wins by filling in the empty spot), and\n- **-10000 (`-1e4`) points** if the opponent has four discs in a row (the opponent won).\n\nThis is defined in the code cell below."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Helper function for minimax: calculates value of heuristic for grid\ndef get_heuristic(grid, mark, config):\n    num_threes = count_windows(grid, 3, mark, config)\n    num_fours = count_windows(grid, 4, mark, config)\n    num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n    num_fours_opp = count_windows(grid, 4, mark%2+1, config)\n    score = num_threes - 1e2*num_threes_opp - 1e4*num_fours_opp + 1e6*num_fours\n    return score"},{"cell_type":"markdown","metadata":{},"source":"In the next code cell, we define a few additional functions that we'll need for the minimax agent.  "},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Uses minimax to calculate value of dropping piece in selected column\ndef score_move(grid, col, mark, config, nsteps):\n    next_grid = drop_piece(grid, col, mark, config)\n    score = minimax(next_grid, nsteps-1, False, mark, config)\n    return score\n\n# Helper function for minimax: checks if agent or opponent has four in a row in the window\ndef is_terminal_window(window, config):\n    return window.count(1) == config.inarow or window.count(2) == config.inarow\n\n# Helper function for minimax: checks if game has ended\ndef is_terminal_node(grid, config):\n    # Check for draw \n    if list(grid[0, :]).count(0) == 0:\n        return True\n    # Check for win: horizontal, vertical, or diagonal\n    # horizontal \n    for row in range(config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[row, col:col+config.inarow])\n            if is_terminal_window(window, config):\n                return True\n    # vertical\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns):\n            window = list(grid[row:row+config.inarow, col])\n            if is_terminal_window(window, config):\n                return True\n    # positive diagonal\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n            if is_terminal_window(window, config):\n                return True\n    # negative diagonal\n    for row in range(config.inarow-1, config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n            if is_terminal_window(window, config):\n                return True\n    return False\n\n# Minimax implementation\ndef minimax(node, depth, maximizingPlayer, mark, config):\n    is_terminal = is_terminal_node(node, config)\n    valid_moves = [c for c in range(config.columns) if node[0][c] == 0]\n    if depth == 0 or is_terminal:\n        return get_heuristic(node, mark, config)\n    if maximizingPlayer:\n        value = -np.Inf\n        for col in valid_moves:\n            child = drop_piece(node, col, mark, config)\n            value = max(value, minimax(child, depth-1, False, mark, config))\n        return value\n    else:\n        value = np.Inf\n        for col in valid_moves:\n            child = drop_piece(node, col, mark%2+1, config)\n            value = min(value, minimax(child, depth-1, True, mark, config))\n        return value"},{"cell_type":"markdown","metadata":{},"source":"We won't describe the minimax implementation in detail, but if you want to read more technical pseudocode, here's the description [from Wikipedia](https://en.wikipedia.org/wiki/Minimax#Pseudocode).  (_Note that the pseudocode can be safely skipped!_)\n\n<center>\n<img src=\"https://i.imgur.com/BwP9tMD.png\" width=60%>\n</center>\n\nFinally, we implement the minimax agent in the competition format.  The `N_STEPS` variable is used to set the depth of the tree."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# How deep to make the game tree: higher values take longer to run!\nN_STEPS = 3\n\ndef agent(obs, config):\n    # Get list of valid moves\n    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n    # Convert the board to a 2D grid\n    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n    # Use the heuristic to assign a score to each possible board in the next step\n    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, config, N_STEPS) for col in valid_moves]))\n    # Get a list of columns (moves) that maximize the heuristic\n    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n    # Select at random from the maximizing columns\n    return random.choice(max_cols)"},{"cell_type":"markdown","metadata":{},"source":"In the next code cell, we see the outcome of one game round against a random agent."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"from kaggle_environments import make, evaluate\n\n# Create the game environment\nenv = make(\"connectx\")\n\n# Two random agents play one game round\nenv.run([agent, \"random\"])\n\n# Show the game\nenv.render(mode=\"ipython\")"},{"cell_type":"markdown","metadata":{},"source":"And we check how we can expect it to perform on average."},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"\ndef get_win_percentages(agent1, agent2, n_rounds=100):\n    # Use default Connect Four setup\n    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n    # Agent 1 goes first (roughly) half the time          \n    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n    # Agent 2 goes first (roughly) half the time      \n    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"get_win_percentages(agent1=agent, agent2=\"random\", n_rounds=50)"},{"cell_type":"markdown","metadata":{},"source":"Not bad!\n\n# Your turn\n\nContinue to check your understanding and **[submit your own agent](https://www.kaggle.com/kernels/fork/8139647)** to the competition."},{"cell_type":"markdown","metadata":{},"source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161477) to chat with other Learners.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":2}